Load libraries.
```{r}
library(numDeriv)
library(ggplot2)
library(dplyr)
library(MASS)
```

Read in COSMOS simulated data.
```{r}
dta <- read.csv('cosmosCVD.csv',
                header = T,
                sep = ',') %>%
    mutate(arm = ifelse(arm == 'placebo', 0, 1))    # placebo = 0, cocoa = 1
```

Define adaptive envelope and squeezing functions.
```{r}
getSlopeInterceptU <- function(xk, f) {
    # this function takes 2 arguments:
    # (1) xk denotes a set of points for fitting envelope and squeezing functions
    # (2) f denotes the function whose density we're trying to simulate
    
    # get the corresponding value of h(x) = log(f(x)) for each xk
    h  <- function(x) {return(log(f(x)))}
    hx <- unlist(lapply(xk, h))
    
    # get the slope of each piecewise linear envelope function h(x)
    # h'(x) = f'(x) / f(x)
    slope  <- function(x) {return(grad(f, x) / f(x))}
    slopes <- unlist(lapply(xk, slope))
    
    # get the intercept of each piecewise linear envelope function h(x)
    # intercept = h(x) - slope * x
    intercepts <- hx - slopes * xk
    
    # get the intersection points of piecewise linear envelope functions
    # intersection point x between j th and j+1 th piecewise is
    # x = (intercept_{j+1} - intercept_j) / (slope_j - slope_{j+1})
    intersections <- (tail(intercepts, -1) - head(intercepts, -1)) / (head(slopes, -1) - tail(slopes, -1))
    
    return(list('slope' = slopes,
                'intercept' = intercepts,
                'intersection' = intersections))
}

gEnvelope <- function(x, envelope) {
    # this functions takes 3 arguments:
    # (1) x denotes the dependent variables
    # (2) envelope denotes the envelope object
    
    #envelope <- getSlopeInterceptU(xk, f)
    
    # find the interval that a certain x belongs to
    i <- findInterval(x, envelope$intersection) + 1
    
    # compute the value of envelope function
    g_u <- exp(envelope$slope[i] * x + envelope$intercept[i])
    return(g_u)
}

getSlopeInterceptL <- function(xk, f) {
    # this function takes 2 arguments:
    # (1) xk denotes a set of points for fitting envelope and squeezing functions
    # (2) f denotes the function whose density we're trying to simulate
    
    # get the corresponding value of h(x) = log(f(x)) for each xk
    h  <- function(x) {return(log(f(x)))}
    hx <- unlist(lapply(xk, h))
    
    # if there are K xk's, then there are K-1 piecewise linear squeezing functions
    # get the slope of each piecewise linear squeezing function
    slopes <- (tail(hx, -1) - head(hx, -1)) / (tail(xk, -1) - head(xk, -1))
    
    # get the intercept of each piecewise linear squeezing function
    intercepts <- head(hx, -1) - head(slopes, -1) * head(xk, -1)
    
    return(list('slope' = slopes,
                'intercept' = intercepts))
}

gSqueezing <- function(x, xk, f) {
    # this functions takes 3 arguments:
    # (1) x denotes the dependent variables
    # (2) xk denotes a set of points for fitting envelope and squeezing functions
    # (3) f denotes the function whose density we're trying to simulate
    
    squeezing <- getSlopeInterceptL(xk, f)
    
    # find the interval that a certain x belongs to
    i <- findInterval(x, xk)
    
    g_l <- c()
    for (j in 1:length(x)) {
        if (i[j] == 0 || i[j] == length(xk)) {
            g_l <- c(g_l, 0)
        } else {
            g_l <- c(g_l,
                     exp(squeezing$slope[i[j]] * x[j] + squeezing$intercept[i[j]]))
        }
    }
    return(g_l)
}

# Squeezing-Rejection test
SRtest <- function(u, l, f, x, xs) {
    # this function takes 5 arguments:
    # (1) u: the value of the envelope function
    # (2) l: the value of the squeezing function
    # (3) f: the value of the original function
    # (4) x: sample that we possibly accept
    # (5) xs: the abcissa set
  
    r <- runif(1)
    if (r <= l/u) {
        # squeezing test
        output = x
    } else if (r <= f/u) {
        # rejection test
        output = x
        xs <- c(xs[xs<x], x, xs[xs>=x])
    } else {
        output = NA
        xs <- c(xs[xs<x], x, xs[xs>=x])
    }
    return(list('x' = output,
                'xs' = xs))
}
```

Define the scheme to sample from the envelope function.
```{r}
getIntervalProb <- function(envelope) {
    # this function takes the whole output of getSlopeInterceptU as input
    slopes <- envelope$slope
    intercepts <- envelope$intercept
    intersections <- envelope$intersection
    
    limits <- c(-Inf, intersections, Inf)    # add +- inf as intersection points as well to aid interval specification
    limits <- cbind(head(limits, -1), tail(limits, -1))
    
    probs <- exp(intercepts) * (exp(limits[, 2]*slopes) - exp(limits[, 1]*slopes))
    
    # if slope == 0, area under curve is exp(intercept) * interval length
    probs[slopes == 0] <- ((limits[, 2] - limits[, 1]) * exp(intercepts))[slopes == 0]
    # if slope != 0, area under curve is given by integral, which is normalized by 1/slope
    probs[slopes != 0] <- probs[slopes != 0] / slopes[slopes != 0]
    
    # return the intervals and the un-normalized weights of each interval
    return(list('intervals' = limits,
                'probs' = probs))
}

sampleEnvelope <- function(intervals, probs, slopes) {
    # this functions takes 2 arguments
    # (1) all the piecewise intervals of envelope functions
    # (2) the weights of all the piecewise intervals
    
    # sample which interval based on weights
    r <- sample(1:nrow(intervals), 1, prob = probs)
    
    # randomly sample from U(0,1) to aid further sampling
    u <- runif(1)
    
    # if the slope is 0, interval is a uniform distribution
    # else the interval has exponential density, then the u can denote the CDF of this exponential density
    # reverse the CDF to get x
    if (slopes[r] == 0) {
        x <- u * (intervals[r, 2] - intervals[r, 1]) + intervals[r, 1]
    } else {
        x <- log(u * exp(slopes[r] * intervals[r, 2]) + (1 - u) * exp(slopes[r] * intervals[r, 1]))
        x <- x / slopes[r]
    }
    return(x)
}
```

Design an algorithm to properly initialize a set of points for envelope function.
```{r}
initAbcissa <- function(x0, f) {
    # this function takes 2 arguments
    # (1) x0, which serves as the seed value for abcissa set construction
    # (2) f, which is the function we're interested in
    xs <- x0
    h <- function(x) {return(log(f(x)))}
    
    dh1 <- 0    # indicator on whether h'(x_1) > 0 is satisfied
    dh2 <- 0    # indicator on whether h'(x_K) < 0 is satisfied
    dx  <- 1    # search stepsize
    ind <- 1    # position where we make the step
    
    while (dh1 + dh2 < 2) {
        if (grad(h, xs[ind]) == 0) {
            if (dh1 == 0) {    # when both are not satisfied, look onto left side first
                x <- xs[ind] - dx
                xs <- c(x, xs)
                
                # if left side is good, switch to right; else keep searching towards left
                ind <- ifelse(grad(h, x) > 0, length(xs), 1)
                dh1 <- ifelse(grad(h, x) > 0, 1, 0)
                dx <- dx * 2    # expand search stepsize
            } else if (dh2 == 0) {
                x <- xs[ind] + dx
                xs <- c(xs, x)
                
                # if right side is good, switch to left; else keep searching towards right
                ind <- ifelse(grad(h, x) < 0, 1, length(xs))
                dh2 <- ifelse(grad(h, x) < 0, 1, 0)
                dx  <- dx * 2    # expand search stepsize
            }
        } else if (grad(h, xs[ind]) > 0) {
            dh1 <- 1
            # if h'(x_1) > 0 is satisfied, search towards right
            x <- xs[ind] + dx
            xs <- c(xs, x)
            
            ind <- length(xs)
            dh2 <- ifelse(grad(h, x) < 0, 1, 0)
            dx  <- dx * 2
        } else {
            dh2 <- 1
            # if h'(x_K) < 0 is satisfied, search towards left
            x <- xs[ind] - dx
            xs <- c(x, xs)
            
            ind <- 1
            dh1 <- ifelse(grad(h, x) > 0, 1, 0)
            dx  <- dx * 2
        }
    }
    
    return(xs)
}

updateAbcissa <- function(xs, f) {
    # this function takes 2 arguments:
    # (1) xs: an existing abcissa set
    # (2) f: the function of interest
    dx <- 1
    h <- function(x) {return(log(f(x)))}
    if (grad(h, xs[1]) <= 0) {
        while (grad(h, xs[1]) <= 0) {
            x <- xs[1] - dx
            xs <- c(x, xs)
            dx <- dx * 2
        }
    } else if (grad(h, xs[length(xs)]) >= 0) {
        while (grad(h, xs[length(xs)]) >= 0) {
            x <- xs[length(xs)] + dx
            xs <- c(xs, x)
            dx <- dx * 2
        }
    }
    return(xs)
}
```

Design the MCMC algorithm. Assume that people in the study were subject to an exponential baseline hazard function, i.e, $H_0(t) = \eta_0t$; we will first set $\eta = 2$ in this run. Also, assume the weight we put on our prior $c_0 = 3$ in this run. We divide total follow-up time into 6-month intervals (i.e., interval length = 0.5 yrs); since the maximum follow-up time was 4 years, there will be $J = 8$ intervals. The beta coefficients have a non-informative prior distribution:

$$\boldsymbol{\beta} \sim N_p(0, 10), ~p=2.$$
```{r}
computeLogLikelihood <- function(dta, beta, h0) {
    # this function takes 5 arguments:
    # (1) dta: the original data (columns: follow-up time, event, arm)
    # (2) beta: the current beta coefficients
    # (3) h0: the current baseline cumulative hazards of each interval; of length J
    J = length(h0)           # number of intervals
    L = max(dta$time) / J    # length of each interval
  
    G <- c()    # vector to store Gj's
    for (j in 1:J) {
        bl <- (j-1)*L    # lower bound of interval
        bu <- j*L        # upper bound of interval
        
        set_risk <- dta %>% filter(time > bl)                              # risk set
        set_fail <- dta %>% filter(event == 1 & time > bl & time <= bu)    # failure set
        set_rnotf <- set_risk %>% anti_join(set_fail, by = 'X')            # people in risk set but not in failure set
        
        # compute the first part of Gj
        rnotf <- cbind(rep(1, nrow(set_rnotf)), set_rnotf$arm)
        part1 <- sum(exp(rnotf %*% beta)) * (-h0[j])
        
        # compute the second part of Gj
        fail <- cbind(rep(1, nrow(set_fail)), set_fail$arm)
        part2 <- sum(log(1 - exp(exp(fail %*% beta) * (-h0[j]))))
        
        Gj <- part1 + part2
        G <- c(G, Gj)
    }
    
    return(sum(G))
}

MCMC <- function(dta, mu0 = c(0,0), sigmasq0 = diag(c(10, 10)), c0 = 3, eta0 = 0.5, kappa0 = 1, L = 2, iter = 2000, x0 = 1) {
    # this function takes 9 arguments:
    # (1) dta: the original data
    # (2) mu0: the prior mean of beta coefficients; of size 2
    # (3) sigmasq0: the prior variance of beta coefficients; of size 2*2
    # (4) c0: the weight we put for Gamma prior of baseline cumulative hazard
    # (5) eta0: hyperparameter of cumulative hazard
    # (6) kappa0: hyperparameter of cumulative hazard
    # (7) L: length of interval
    # (8) iter: number of iterations
    # (9) x0: the seed number of construct abcissa set
    
    # initialize matrix of beta coefficients
    beta_mat <- matrix(rep(mvrnorm(1, mu0, sigmasq0), iter), byrow = T, nrow = iter)
    # initialize matrix of cumulative hazard h0
    t <- max(dta$time)
    if (t %% L == 0) {
        J <- t %/% L
    } else {
        J <- t %/% L + 1
    }
    I <- c(0, 1:(J-1)*L, t)
    h0_mean <- eta0 * (tail(I, -1) - head(I, -1))^kappa0
    h0_mat <- matrix(rep(rgamma(J, shape = c0*h0_mean, rate = c0), iter), byrow = T, nrow = iter)
    # get dj's, the number of failures in each interval
    d <- c()
    for (j in 1:J) {
        set_fail <- dta %>% filter(event == 1 & time > (j-1)*L & time <= j*L)
        d <- c(d, nrow(set_fail))
    }
    
    for (i in 2:iter) {
        ### first part: sample each beta coefficient ###
        
        # for beta0
        # define the function of interest
        f0 <- function(beta0) {
            b <- c(beta0, beta_mat[i-1, 2])
            # likelihood
            LH <- exp(computeLogLikelihood(dta, b, h0_mat[i-1, ]))
            # normal probability
            NP <- exp(-0.5 * ((t(b - mu0) %*% solve(sigmasq0)) %*% (b - mu0)))
            return(LH * NP)
        }
        # get the abcissa set
        if (i == 2) {
            xs0 <- initAbcissa(x0, f0)
        } else {
            xs0 <- updateAbcissa(xs0, f0)
        }
        # get the attributes of envelope function
        envelope0 <- getSlopeInterceptU(xs0, f0)
        intervalDesign0 <- getIntervalProb(envelope0)
        # sample a new beta0
        b0_sampled <- sampleEnvelope(intervalDesign0$intervals,
                                     intervalDesign0$probs,
                                     envelope0$slope)
        fx0 <- f0(b0_sampled)
        g_u0 <- gEnvelope(b0_sampled, envelope0)
        g_l0 <- gSqueezing(b0_sampled, xs0, f0)
        # carry out squeezing-rejection test
        srt0 <- SRtest(g_u0, g_l0, fx0, b0_sampled, xs0)
        # update abcissa set and 
        xs0 <- srt0$xs
        beta_mat[i, 1] <- ifelse(is.na(srt0$x), beta_mat[i-1, 1], srt0$x)
        
        # for beta1
        # define the function of interest
        f1 <- function(beta1) {
            b <- c(beta_mat[i, 1], beta1)
            # likelihood
            LH <- exp(computeLogLikelihood(dta, b, h0_mat[i-1, ]))
            # normal probability
            NP <- exp(-0.5 * ((t(b - mu0) %*% solve(sigmasq0)) %*% (b - mu0)))
            return(LH * NP)
        }
        # get the abcissa set
        if (i == 2) {
            xs1 <- initAbcissa(x0, f1)
        } else {
            xs1 <- updateAbcissa(xs1, f1)
        }
        # get the attributes of envelope function
        envelope1 <- getSlopeInterceptU(xs1, f1)
        intervalDesign1 <- getIntervalProb(envelope1)
        # sample a new beta0
        b1_sampled <- sampleEnvelope(intervalDesign1$intervals,
                                     intervalDesign1$probs,
                                     envelope1$slope)
        fx1 <- f1(b1_sampled)
        g_u1 <- gEnvelope(b1_sampled, envelope1)
        g_l1 <- gSqueezing(b1_sampled, xs1, f1)
        # carry out squeezing-rejection test
        srt1 <- SRtest(g_u1, g_l1, fx1, b1_sampled, xs1)
        # update abcissa set and 
        xs1 <- srt1$xs
        beta_mat[i, 2] <- ifelse(is.na(srt1$x), beta_mat[i-1, 2], srt1$x)
        
        ### second part: sample each interval's cumulative hazard ###
        rnf <- c()
        for (j in 1:J) {
            bl <- (j-1)*L    # lower bound of interval
            bu <- j*L        # upper bound of interval
        
            set_risk <- dta %>% filter(time > bl)                              # risk set
            set_fail <- dta %>% filter(event == 1 & time > bl & time <= bu)    # failure set
            set_rnotf <- set_risk %>% anti_join(set_fail, by = 'X')            # people in risk set but not in failure set
            
            rnotf <- cbind(rep(1, nrow(set_rnotf)), set_rnotf$arm)
            val <- sum(exp(rnotf %*% beta_mat[i, ]))
            rnf <- c(rnf, val)
        }
        h0_sampled <- rgamma(J, shape = c0*h0_mean + d, rate = c0 + rnf)
        h0_mat[i, ] <- h0_sampled
    }
    
    return(cbind(beta_mat, h0_mat))
}
```

Construct a sample dataset with much smaller size.
```{r}
set.seed(292875)
s1 <- sample(1:410, 10)
s2 <- sample(411:10723, 10)
s3 <- sample(10724:11133, 10)
s4 <- sample(11134:21442, 10)
dta_1 <- dta[c(s1,s2,s3,s4),]
```

Example running of MCMC.
```{r}
df <- MCMC(dta_1, iter = 1000, x0 = 0)
print(df)
```
